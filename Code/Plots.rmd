---
title: "Plots"
author: "Markus Gerholm"
date: "2025-12-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading cleaned data

```{r}
setwd("..")
source("Code/sweden_returns_washed.R")
```

## png of all asset names

```{r}
library(gridExtra)
library(grid)

assets <- sort(colnames(df_clean))   # or rownames(df_clean)
n_col  <- 20
n_row  <- ceiling(length(assets) / n_col)

mat <- matrix("", nrow = n_row, ncol = n_col)
mat[1:length(assets)] <- assets
colnames(mat) <- rep("", n_col)

# shrink text with cex; lower = smaller text
txt_cex <- 0.4   # try 0.5, 0.4, 0.3

tt <- ttheme_minimal(
  core = list(fg_params = list(cex = txt_cex)),
  colhead = list(fg_params = list(cex = txt_cex))
)

tbl <- tableGrob(mat, rows = NULL, theme = tt)

# make a bigger image so the tiny text is still readable when you insert it
png("asset_names.png", width = 2400, height = 1400, <- = 200)
grid.draw(tbl)
dev.off()

```

## some plots of the log returns

```{r}
set.seed(132)

# date column
df_clean$X <- as.Date(df_clean$X)   # adjust format if needed
dates <- df_clean$X

# pick 16 random assets (excluding date column)
all_assets <- setdiff(colnames(df_clean), "X")
assets_16  <- sample(all_assets, 16)

# common ylim across all 16
ylim_common <- range(df_clean[assets_16], na.rm = TRUE)

# split into first and second half
first_half  <- assets_16[1:8]
second_half <- assets_16[9:16]
```

## Log returns of 8 stocks

```{r}
## First figure: first half (8 assets)
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in first_half) {
  plot(dates, df_clean[[nm]],
       type = "l",
       main = nm,
       xlab = "",
       ylab = "",
       xaxt = "n",
       ylim = ylim_common,
       col = "blue")
  axis.Date(1,
            at = seq(min(dates), max(dates), by = "year"),
            format = "%Y",
            cex.axis = 0.7)
}
```

## Log returns of 8 stocks

```{r}
## Second figure: second half (8 assets)
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in second_half) {
  plot(dates, df_clean[[nm]],
       type = "l",
       main = nm,
       xlab = "",
       ylab = "",
       xaxt = "n",
       ylim = ylim_common,
       col = "blue")
  axis.Date(1,
            at = seq(min(dates), max(dates), by = "year"),
            format = "%Y",
            cex.axis = 0.7)
}
```

## QQ-plots and QQ-line for the log returns

## First half

```{r}
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in first_half) {
  qqnorm(df_clean[[nm]], main = paste("Q-Q Plot: ", nm))
  qqline(df_clean[[nm]], col = "red")
}
```

## Second half

```{r}
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in second_half) {
  qqnorm(df_clean[[nm]], main = paste("Q-Q Plot: ", nm))
  qqline(df_clean[[nm]], col = "red")
}

```

## Standardizing through Stochastic Volatility (Bayesian MCMC method for posterior distribution)

```{r}
set.seed(132)
library(stochvol)
library(xts)

sv_standardize_xts <- function(r_xts, draws = 4000, burnin = 1000) {
  y <- as.numeric(r_xts)
  y <- y - mean(y)

  fit <- svsample(y, draws = draws, burnin = burnin, quiet = TRUE)
  sig_hat <- colMeans(vola(fit))
  z <- y / sig_hat
  xts(z, order.by = index(r_xts))
}

assets <- setdiff(names(df_clean), "X")
R_xts <- xts(as.matrix(df_clean[, assets]), order.by = df_clean$X)

# SV-standardize EVERY asset column
Z_xts <- do.call(merge, lapply(colnames(R_xts), function(nm) {
  z <- sv_standardize_xts(R_xts[, nm, drop = FALSE], draws = 2000, burnin = 500)
  colnames(z) <- nm
  z
}))

# convert to a data.frame with dates
Z_df <- data.frame(X = as.Date(index(Z_xts)), coredata(Z_xts))

```

## Q-Q plots after Stochastic Volatility standardized log returns

## First half

```{r}
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in first_half) {
  qqnorm(Z_df[[nm]], main = paste("Q-Q Plot: ", nm))
  qqline(Z_df[[nm]], col = "red")
}
```

## Second half

```{r}
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in second_half) {
  qqnorm(Z_df[[nm]], main = paste("Q-Q Plot: ", nm))
  qqline(Z_df[[nm]], col = "red")
}
```
## Standardizing through GARCH(1,1)

```{r}
library(rugarch)

## 1) GARCH(1,1) specification (Student-t innovations)
spec <- ugarchspec(
  variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
  mean.model     = list(armaOrder = c(0, 0), include.mean = TRUE),
  distribution.model = "std"
)

## 2) Function to GARCH-standardize each column of a T x n matrix/data.frame
garch_standardize_matrix <- function(M, spec) {
  M <- as.matrix(M)
  Tn <- nrow(M)
  nn <- ncol(M)
  
  Z <- sapply(seq_len(nn), function(j) {
    x <- as.numeric(M[, j])
    
    # Fit GARCH(1,1); you can add tryCatch if some series fail
    fit <- ugarchfit(spec = spec, data = x, solver = "hybrid")
    
    # Standardized residuals (epsilon_t / sigma_t)
    as.numeric(residuals(fit, standardize = TRUE))
  })
  
  colnames(Z) <- colnames(M)
  Z
}

## 3) Apply to your asset returns in df_clean (exclude X)
asset_cols <- setdiff(colnames(df_clean), "X")
R_mat      <- as.matrix(df_clean[, asset_cols])

Zgarch     <- garch_standardize_matrix(R_mat, spec = spec)
Zgarch_df  <- as.data.frame(Zgarch)

## 4) (Optional) add back the date column X
Zgarch_df$X <- df_clean$X
# If you want X first:
Zgarch_df   <- Zgarch_df[, c("X", asset_cols)]

```

## Q-Q Plots of GARCH standardized log returns

## First half

```{r}
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in first_half) {
  qqnorm(Zgarch_df[[nm]], main = paste("Q-Q Plot: ", nm))
  qqline(Zgarch_df[[nm]], col = "red")
}
```


## Second half

```{r}
par(mfrow = c(2, 4), mar = c(3, 3, 2, 1))

for (nm in second_half) {
  qqnorm(Zgarch_df[[nm]], main = paste("Q-Q Plot: ", nm))
  qqline(Zgarch_df[[nm]], col = "red")
}
```

## Ensuring zero mean

```{r}
Z_0 <- coredata(Z_xts)
Z_0 <- scale(Z_0, center = TRUE, scale = FALSE)
```

## Checking normality over time

```{r}
asset <- "MVIR.ST"  # change to any column name
x <- Z_df[[asset]]

window_size <- 250
n <- length(x)

starts <- seq(1, n - window_size + 1, by = window_size)

par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))  # 6 panels per page

for (i in seq_along(starts)) {
  idx <- starts[i]:(starts[i] + window_size - 1)
  x_win <- x[idx]

  qqnorm(x_win,
         main = paste0(asset, " | days ", idx[1], "–", idx[length(idx)]))
  qqline(x_win, col = "red")
}
```

```{r}
asset <- "QIIWI.ST"  # change to any column name
x <- Z_df[[asset]]

window_size <- 250
n <- length(x)

starts <- seq(1, n - window_size + 1, by = window_size)

par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))  # 6 panels per page

for (i in seq_along(starts)) {
  idx <- starts[i]:(starts[i] + window_size - 1)
  x_win <- x[idx]

  qqnorm(x_win,
         main = paste0(asset, " | days ", idx[1], "–", idx[length(idx)]))
  qqline(x_win, col = "red")
}
```

## Regular GLASSO on time intervals
```{r}
library(huge)

## --- 1. Define windows (same as in your QQ plot example) ---
window_size <- 250
n <- nrow(Z_0)   # number of time points

starts <- seq(1, n - window_size + 1, by = window_size)

## --- 2. Glasso settings ---
tol <- 1e-6            # for turning precision into adjacency later, if needed

## --- 3. Fit glasso in each window ---
glasso_list <- vector("list", length(starts))
names(glasso_list) <- paste0("win_", seq_along(starts))

for (i in seq_along(starts)) {
  idx   <- starts[i]:(starts[i] + window_size - 1)
  Z_win <- as.matrix(Z_0[idx, , drop = FALSE])  # 250 × p window

  fit <- huge(
    Z_win,
    method       = "glasso",
    lambda = c(0.5, 0.35, 0.20)
  )

  glasso_list[[i]] <- fit
}

## --- 4. Extract precision matrices and adjacencies for each window ---
icov_list <- lapply(glasso_list, function(fit) fit$icov[[1]])  # first (only) lambda

adj_list <- lapply(icov_list, function(Omega) {
  A <- (abs(Omega) > tol) * 1
  diag(A) <- 0
  A
})
```
## Plots of regular GLASSO for the four different time periods with three different values of lambda

```{r}
plot(glasso_list[[1]])  
plot(glasso_list[[2]]) 
plot(glasso_list[[3]]) 
plot(glasso_list[[4]])
```


## Modelling time series through tvglasso

```{r}
library(igraph)
library(tvsfglasso)
Y <- t(Z_0) # row = assets, cols = time points
N = ncol(Y) # number of time points
pos <- 1:N # length of data as sequence
res <- tvglasso(Y = Y, N = N, pos = pos, rep = FALSE, lambda = 0.7, h = 0.025) # fitting tvglasso model
```

## Adding sectors to dataset

```{r}
log_returns <- xts(df_clean[ , -1], order.by = as.Date(df_clean$X))
#log_returns <- log_returns[, colSums(is.na(log_returns)) == 0]
library(readxl)
library(dplyr)

# Read sectors
sectors_df <- read_excel("../Data/Sectors.xlsx")  # Columns: Symbol, Sector

# Tickers from log_returns
tickers <- colnames(log_returns)

# Normalize
tickers <- toupper(trimws(tickers))
sectors_df$Symbol <- toupper(trimws(sectors_df$Symbol))

# Add .ST to match Yahoo tickers
sectors_df$Yahoo_Ticker <- paste0(sectors_df$Symbol, ".ST")

# Create a named vector for mapping
sector_map <- setNames(sectors_df$Sector, sectors_df$Yahoo_Ticker)

# Map tickers to sectors
ticker_sectors_Z0 <- sector_map[tickers]

# Identify tickers without a sector
missing_tickers <- tickers[is.na(ticker_sectors_Z0)]
if(length(missing_tickers) > 0){
  cat("These tickers have no matching sector:\n")
  print(missing_tickers)
}
```

## Plot of Time-Varying GLASSO at t = 1

```{r}
library(igraph)

## --- 1) Precision & partial correlations at t = 1 ---
Omega1 <- res$icov[[1]]

# partial correlation matrix
d  <- sqrt(diag(Omega1))
P1 <- -Omega1 / (d %o% d)
diag(P1) <- 0

## --- 2) Build graph with weights = partial correlations ---
g1 <- graph_from_adjacency_matrix(P1, mode = "undirected", weighted = TRUE, diag = FALSE)

# optionally drop very small edges
#tol <- 0.01   # tweak this threshold
#g1  <- delete_edges(g1, E(g1)[abs(weight) < tol])

## --- 3) Layout: same filled-circle layout as before ---
set.seed(1)
n <- vcount(g1)
theta <- runif(n, 0, 2*pi)
r     <- sqrt(runif(n, 0, 1))
lay_disk <- cbind(r * cos(theta), r * sin(theta))

## --- 4) Color code edges by |partial corr| (3 cutoffs, 3 reds) ---
abs_w <- abs(E(g1)$weight)

# choose your cutoffs (in terms of |partial corr|)
cuts <- c(0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.45, Inf )  # 0–0.05, 0.05–0.10, >0.10

# 13 bins total
n_bins <- length(cuts) - 1      # 13
n_red  <- n_bins - 1            # 12 red bins (everything above 0.05)

# gray for the first bin, then 12 reds from light to dark
reds <- colorRampPalette(c("#ffcccc", "#7f0000"))(n_red)
pal  <- c("grey80", reds)

# map to 3 levels
lev  <- cut(abs_w, breaks = cuts, include.lowest = TRUE, labels = FALSE)

# palette: light -> medium -> dark red
#pal <- c("gray", "#ff6666", "#990000")

E(g1)$color <- pal[lev]

# optionally make thicker lines for stronger edges
E(g1)$width <- 0.5 + lev   # 1, 2, 3

## --- 5) Plot ---
par(mar = c(0, 0, 0, 0))

plot(
  g1,
  layout             = lay_disk,
  vertex.size        = 3,
  vertex.label       = NA,
  vertex.color       = "black",
  vertex.frame.color = NA,
  edge.color         = E(g1)$color,
  edge.width         = E(g1)$width,
  xlim               = c(-1.1, 1.1),
  ylim               = c(-1.1, 1.1),
  asp                = 1,
  axes               = FALSE
)

symbols(0, 0, circles = 1.05, inches = FALSE, add = TRUE, lwd = 2, fg = "black")
```

## Max partial correlation between A,B assets

```{r}
## helper: partial correlation from precision
pcor_from_icov <- function(Omega) {
  d <- sqrt(diag(Omega))
  P <- -Omega / (d %o% d)
  diag(P) <- 0
  P
}

Tn <- length(res$icov)

# asset names from Z_0 (assumes same order as rows/cols in res$icov)
asset_names <- colnames(Z_0)
if (is.null(asset_names)) stop("Z_0 needs column names for assets.")

# dates aligned with time index (optional; comment out if not needed)
dates <- as.Date(df_clean$X)   # ensure df_clean$X is Date or convert before

## 1) Identify A/B pairs from asset_names -----------------------------

# adjust regex if your naming differs; here we assume e.g. VOLV.A.ST, VOLV.B.ST
is_A <- grepl("\\.A(\\.|$)", asset_names)
is_B <- grepl("\\.B(\\.|$)", asset_names)

roots_A <- sub("\\.A(\\.|$).*", "", asset_names[is_A])
roots_B <- sub("\\.B(\\.|$).*", "", asset_names[is_B])

common_roots <- intersect(roots_A, roots_B)

# build mapping: root -> A name, B name, and indices
ab_pairs <- lapply(common_roots, function(root) {
  nameA <- asset_names[is_A][which(roots_A == root)[1]]
  nameB <- asset_names[is_B][which(roots_B == root)[1]]
  i <- match(nameA, asset_names)
  j <- match(nameB, asset_names)
  list(root = root, A = nameA, B = nameB, i = i, j = j)
})

## 2) For each A/B pair, find maximum partial correlation over time ----

results <- lapply(ab_pairs, function(pair) {
  i <- pair$i
  j <- pair$j

  best_val <- -Inf
  best_t   <- NA_integer_

  for (t in seq_len(Tn)) {
    P_t <- pcor_from_icov(res$icov[[t]])
    val <- P_t[i, j]
    if (!is.na(val) && val > best_val) {
      best_val <- val
      best_t   <- t
    }
  }

  data.frame(
    root        = pair$root,
    asset_A     = pair$A,
    asset_B     = pair$B,
    max_pcor    = best_val,
    t_index     = best_t,
    date_at_max = dates[best_t],
    stringsAsFactors = FALSE
  )
})

ab_max_pcor_df <- do.call(rbind, results)

# sort by highest max partial correlation
ab_max_pcor_df <- ab_max_pcor_df[order(-ab_max_pcor_df$max_pcor), ]

ab_max_pcor_df
```

## GIF of Time-Varying GLASSO

```{r}
library(igraph)
library(gifski)

## dates aligned with columns of Y / rows of Z_0
dates <- as.Date(df_clean$X)   # adjust if needed

# which time points to include
T_idx <- seq_along(res$icov)

cuts <- c(0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.45, Inf)
n_bins <- length(cuts) - 1
n_red  <- n_bins - 1

reds <- colorRampPalette(c("#ffcccc", "#7f0000"))(n_red)
pal  <- c("grey80", reds)

pcor_from_icov <- function(Omega) {
  d <- sqrt(diag(Omega))
  P <- -Omega / (d %o% d)
  diag(P) <- 0
  P
}

## reference layout at t = 300
t_layout <- 300
Omega_ref <- res$icov[[t_layout]]
P_ref     <- pcor_from_icov(Omega_ref)

g_ref <- graph_from_adjacency_matrix(P_ref, mode = "undirected",
                                     weighted = TRUE, diag = FALSE)

set.seed(1)
n <- vcount(g_ref)
theta <- runif(n, 0, 2*pi)
r     <- sqrt(runif(n, 0, 1))
lay_disk <- cbind(r * cos(theta), r * sin(theta))

save_gif({
  op <- par(mar = c(0, 0, 0, 0))
  on.exit(par(op), add = TRUE)

  for (t in T_idx) {
    Omega_t <- res$icov[[t]]
    P_t     <- pcor_from_icov(Omega_t)

    g_t <- graph_from_adjacency_matrix(P_t, mode = "undirected",
                                       weighted = TRUE, diag = FALSE)

    abs_w <- abs(E(g_t)$weight)
    lev   <- cut(abs_w, breaks = cuts, include.lowest = TRUE, labels = FALSE)
    lev[is.na(lev)] <- 1

    E(g_t)$color <- pal[lev]
    E(g_t)$width <- 0.5 + lev * 0.3

    plot(
      g_t,
      layout             = lay_disk,
      vertex.size        = 3,
      vertex.label       = NA,
      vertex.color       = "black",
      vertex.frame.color = NA,
      edge.color         = E(g_t)$color,
      edge.width         = E(g_t)$width,
      xlim               = c(-1.1, 1.1),
      ylim               = c(-1.1, 1.1),
      asp                = 1,
      axes               = FALSE
    )

    symbols(0, 0, circles = 1.05, inches = FALSE,
            add = TRUE, lwd = 2, fg = "black")

    # ---- time + year + month label ----
    lab_date <- format(dates[t], "%b %Y")  # e.g. "Mar 2020"
    
    usr <- par("usr")
    x0  <- usr[1]
    y0  <- usr[4]
    
    # move down by 4% of the plot height
    x_offset <- 0.04 * (usr[2] - usr[1])   # move right
    y_offset <- 0.04 * (usr[4] - usr[3])   # move down
    
    text(
    x0 + x_offset, y0 - y_offset,
    labels = paste0("t = ", t, "   ", lab_date),
    adj = c(0, 1),   # left-aligned, top of text at (x,y)
    xpd = NA,
    cex = 1.4        # increase for larger text (try 1.2–1.6)
    )

  }
}, gif_file = "tvglasso_circle_pcor_year.gif",
   width = 800, height = 800, delay = 0.08)


```

## Plot of Time-Varying GLASSO with sectors at t = 300

```{r}
library(igraph)
library(RColorBrewer)

## --- 0) Asset & sector mapping from Z_0 ---

asset_names <- colnames(Z_0)          # tickers, same order as rows/cols in Omega
sectors_all <- ticker_sectors_Z0      # named vector: names = tickers, values = sectors

## --- 1) Precision & partial correlations at t = 1 ---
Omega1 <- res$icov[[300]]

# partial correlation matrix
d  <- sqrt(diag(Omega1))
P1 <- -Omega1 / (d %o% d)
diag(P1) <- 0

# give names so igraph keeps them
dimnames(P1) <- list(asset_names, asset_names)

## --- 2) Build graph with weights = partial correlations ---
g1 <- graph_from_adjacency_matrix(P1, mode = "undirected",
                                  weighted = TRUE, diag = FALSE)

## --- 2b) Vertex sectors + colors ---

# sectors in vertex order
sector_levels <- sort(unique(sectors_v))
n_sec <- length(sector_levels)

# base palette (similar to before)
if (n_sec <= 8) {
  sector_cols <- brewer.pal(n_sec, "Set2")
} else {
  sector_cols <- rainbow(n_sec)
}
names(sector_cols) <- sector_levels

# --- manual tweaks for better separation ---

# Utilities: strong purple
if ("Utilities" %in% sector_levels) {
  sector_cols[sector_levels == "Utilities"] <- "#984ea3"  # purple
}

# Technology / Information Technology: clear blue
if ("Technology" %in% sector_levels) {
  sector_cols[sector_levels == "Technology"] <- "#377eb8" # blue
}
if ("Information Technology" %in% sector_levels) {
  sector_cols[sector_levels == "Information Technology"] <- "#377eb8"
}

# Materials: vivid green
if ("Materials" %in% sector_levels) {
  sector_cols[sector_levels == "Materials"] <- "#4daf4a"  # green
}

# Real Estate: strong orange/red
if ("Real Estate" %in% sector_levels) {
  sector_cols[sector_levels == "Real Estate"] <- "#e41a1c" # red/orange
}


V(g1)$color <- sector_cols[sectors_v]

## --- 3) Layout: group by sector in wedges of a filled circle ---

set.seed(1)
n <- vcount(g1)

lay_disk <- matrix(NA_real_, nrow = n, ncol = 2)
rownames(lay_disk) <- V(g1)$name

# each sector gets an angular wedge
angle_min <- 0
angle_max <- 2 * pi
sector_width <- (angle_max - angle_min) / n_sec

for (s_idx in seq_along(sector_levels)) {
  sec <- sector_levels[s_idx]
  vidx <- which(sectors_v == sec)  # vertices in this sector

  # wedge for this sector
  start_angle <- angle_min + (s_idx - 1) * sector_width
  end_angle   <- start_angle + sector_width

  # random angles within wedge
  theta <- runif(length(vidx), start_angle, end_angle)
  # random radii for filled disk
  r     <- sqrt(runif(length(vidx), 0, 1))

  lay_disk[vidx, ] <- cbind(r * cos(theta), r * sin(theta))
}

## --- 4) Edge colors by |partial corr| bins ---

abs_w <- abs(E(g1)$weight)

cuts <- c(0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.45, Inf)

n_bins <- length(cuts) - 1
n_red  <- n_bins - 1

reds <- colorRampPalette(c("#ffcccc", "#7f0000"))(n_red)
pal  <- c("grey80", reds)

lev <- cut(abs_w, breaks = cuts, include.lowest = TRUE, labels = FALSE)
lev[is.na(lev)] <- 1

E(g1)$color <- pal[lev]
E(g1)$width <- 0.5 + lev

## --- 5) Plot ---
par(mar = c(0, 0, 0, 0))

plot(
  g1,
  layout             = lay_disk,
  vertex.size        = 3,
  vertex.label       = NA,
  vertex.color       = V(g1)$color,   # sector colors
  vertex.frame.color = NA,
  edge.color         = E(g1)$color,
  edge.width         = E(g1)$width,
  xlim               = c(-1.1, 1.1),
  ylim               = c(-1.1, 1.1),
  asp                = 1,
  axes               = FALSE
)

symbols(0, 0, circles = 1.15, inches = FALSE,
        add = TRUE, lwd = 2, fg = "black")

legend("bottomleft",
       legend = sector_levels,
       col    = sector_cols,
       pch    = 16,
       bty    = "n",
       cex    = 0.6)

```

## GIF of Time-Varying GLASSO with sectors

```{r}
sector_color_map <- c(
  "Financials"            = "#33a02c",   # green
  "Industrials"           = "#ff7f00",   # orange
  "Consumer Discretionary"= "yellow",   # green
  "Consumer Staples"      = "#b15928",   # brown
  "Technology"            = "#377eb8",   # strong blue
  "Utilities"             = "#984ea3",   # purple
  "Healthcare"            = "#e31a1c",   # red
  "Real Estate"           = "cyan",   # soft red
  "Materials"             = "darkgreen",   # vivid green
  "Energy"                = "pink",   # light blue
  "Communication Services"= "magenta"    # pink
)
#colnames(Z_0)[colnames(Z_0) == "X2CUREX.ST"] <- "2CUREX.ST"

```


```{r}
library(igraph)
library(RColorBrewer)
library(gifski)

## --- 0) Assets, sectors, dates ---

asset_names <- colnames(Z_0)          # tickers, same order as rows/cols in res$icov
sectors_all <- ticker_sectors_Z0      # named vector: names = tickers, values = sectors

# sectors in asset order
sectors_v <- sectors_all[asset_names]

# safety check
if (any(is.na(sectors_v))) {
  cat("Assets with missing sector mapping:\n")
  print(asset_names[is.na(sectors_v)])
  stop("Fix sector mapping before plotting.")
}

sector_levels <- sort(unique(sectors_v))
n_sec <- length(sector_levels)

# ---- HARD-CODED SECTOR COLORS ----

# ensure all sectors in your data exist in map
unknown_sectors <- setdiff(sector_levels, names(sector_color_map))
if (length(unknown_sectors) > 0) {
  stop("Missing colors for sectors: ", paste(unknown_sectors, collapse = ", "))
}

# final color vector aligned with sector_levels
sector_cols <- sector_color_map[sector_levels]

# dates aligned with time index
dates <- as.Date(df_clean$X)

## --- 1) Sector-grouped filled-circle layout (fixed for all t) ---

set.seed(1)
p <- length(asset_names)

lay_disk <- matrix(NA_real_, nrow = p, ncol = 2)
rownames(lay_disk) <- asset_names

angle_min <- 0
angle_max <- 2 * pi
sector_width <- (angle_max - angle_min) / n_sec

for (s_idx in seq_along(sector_levels)) {
  sec  <- sector_levels[s_idx]
  vidx <- which(sectors_v == sec)    # asset indices in this sector

  start_angle <- angle_min + (s_idx - 1) * sector_width
  end_angle   <- start_angle + sector_width

  theta <- runif(length(vidx), start_angle, end_angle)
  r     <- sqrt(runif(length(vidx), 0, 1))

  lay_disk[vidx, ] <- cbind(r * cos(theta), r * sin(theta))
}

if (any(is.na(lay_disk))) stop("Layout contains NA coordinates; check sector mapping.")

## --- 2) Helper: partial correlation from precision ---

pcor_from_icov <- function(Omega) {
  d <- sqrt(diag(Omega))
  P <- -Omega / (d %o% d)
  diag(P) <- 0
  P
}

## --- 3) Edge color bins for |partial corr| ---

cuts <- c(0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.45, Inf)
n_bins <- length(cuts) - 1
n_red  <- n_bins - 1

reds <- colorRampPalette(c("#ffcccc", "#7f0000"))(n_red)
pal  <- c("grey80", reds)   # first bin = grey, rest reds

## --- 4) Time indices to include in GIF ---

Ts <- seq_along(res$icov)   # all time points
# e.g. use every 5th: Ts <- seq(1, length(res$icov), by = 5)

## --- 5) Build GIF ---

save_gif({
  op <- par(mar = c(0, 0, 0, 0))
  on.exit(par(op), add = TRUE)

  for (t in Ts) {
    Omega_t <- res$icov[[t]]
    P_t     <- pcor_from_icov(Omega_t)

    # Graph at time t (vertex order matches asset_names)
    g_t <- graph_from_adjacency_matrix(
      P_t,
      mode     = "undirected",
      weighted = TRUE,
      diag     = FALSE
    )

    # Edge colors by |partial corr| bins
    abs_w <- abs(E(g_t)$weight)
    lev   <- cut(abs_w, breaks = cuts, include.lowest = TRUE, labels = FALSE)
    lev[is.na(lev)] <- 1

    E(g_t)$color <- pal[lev]
    E(g_t)$width <- 0.5 + lev      # thicker for stronger edges

    # Node colors by sector (in asset order)
    vcols <- sector_cols[sectors_v]

    plot(
      g_t,
      layout             = lay_disk,
      vertex.size        = 3,
      vertex.label       = NA,
      vertex.color       = vcols,
      vertex.frame.color = NA,
      edge.color         = E(g_t)$color,
      edge.width         = E(g_t)$width,
      xlim               = c(-1.15, 1.15),
      ylim               = c(-1.15, 1.15),
      asp                = 1,
      axes               = FALSE
    )

    # circle border
    symbols(0, 0, circles = 1.15, inches = FALSE,
            add = TRUE, lwd = 2, fg = "black")

    # sector legend
    legend("bottomleft",
           legend = sector_levels,
           col    = sector_cols,
           pch    = 16,
           bty    = "n",
           cex    = 0.6)

    # ---- t + month/year label ----
    lab_date <- format(dates[t], "%b %Y")  # e.g. "Mar 2020"
    usr <- par("usr")
    x0  <- usr[1]
    y0  <- usr[4]

    x_offset <- 0.04 * (usr[2] - usr[1])   # move right
    y_offset <- 0.04 * (usr[4] - usr[3])   # move down

    text(
      x0 + x_offset,
      y0 - y_offset,
      labels = paste0("t = ", t, "   ", lab_date),
      adj = c(0, 1),   # left, top
      xpd = NA,
      cex = 1.4
    )
  }
}, gif_file = "tvglasso_sector_circle.gif",
   width = 800, height = 800, delay = 0.08)

```

```{r}
cuts <- c(0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.45, Inf)
n_bins <- length(cuts) - 1
n_red  <- n_bins - 1

reds <- colorRampPalette(c("#ffcccc", "#7f0000"))(n_red)
pal  <- c("grey80", reds)

max_finite <- cuts[length(cuts) - 1]

# fine grid along y
y <- seq(0, max_finite, length.out = 500)
bin_idx <- findInterval(y, cuts, rightmost.closed = TRUE)
bin_idx[bin_idx == 0] <- 1
cols_bar <- pal[bin_idx]

par(mar = c(4, 5, 2, 2))

# note: xlim is narrow now
plot(NA, xlim = c(0, 0.2), ylim = c(0, max_finite),
     xlab = "", ylab = "|partial correlation|",
     xaxt = "n", yaxt = "n")

dy <- diff(y)[1]
x_left  <- 0.012
x_right <- 0.001   # thin bar between 0.05 and 0.15 on x

for (i in seq_along(y)) {
  rect(x_left, y[i] - dy/2, x_right, y[i] + dy/2,
       col = cols_bar[i], border = NA)
}

finite_cuts <- cuts[1:(length(cuts) - 1)]
abline(h = finite_cuts, col = "white", lwd = 1)

axis(2,
     at = finite_cuts,
     labels = formatC(finite_cuts, digits = 2, format = "f"),
     las = 1)

```


```{r}
library(gifski)

pcor_from_icov <- function(M) {
  d <- sqrt(diag(M))
  P <- -M / (d %o% d)
  diag(P) <- 0
  P
}

# dates aligned with res$icov time index
dates <- as.Date(df_clean$X)  # adjust if needed

cap  <- 0.05  # try 0.05, 0.08, 0.10, 0.15
zlim <- c(-cap, cap)

cols   <- colorRampPalette(c("darkblue","white","red"))(256)
breaks <- seq(zlim[1], zlim[2], length.out = length(cols) + 1)

Ts <- seq(1, length(res$icov), by = 1)

save_gif({
  par(mar = c(0,0,2,0))
  for (t in Ts) {
    P <- pcor_from_icov(res$icov[[t]])
    P <- pmax(pmin(P, zlim[2]), zlim[1])   # clamp

    image(
      t(P[nrow(P):1, ]),
      col    = cols,
      breaks = breaks,
      axes   = FALSE,
      useRaster = TRUE
    )

    # ---- t + month/year label ----
    lab_date <- format(dates[t], "%b %Y")  # e.g. "Mar 2020"
    usr <- par("usr")
    x0  <- usr[1]
    y0  <- usr[4]

    # small offsets as % of width/height
    x_offset <- 0.04 * (usr[2] - usr[1])   # move right
    y_offset <- 0.04 * (usr[4] - usr[3])   # move down

    text(
      x0 + x_offset,
      y0 - y_offset,
      labels = paste0("t = ", t, "   ", lab_date),
      adj = c(0, 1),   # left, top
      xpd = NA,
      cex = 1.4
    )

    # optional title above
    title(main = paste0("Partial correlation (capped at ±", cap, ")"), line = 1)
  }
}, gif_file = "pcor_heatmap_capped.gif", width = 800, height = 800, delay = 0.03)

```


## Average volatility as rolling window (window size = 20)

```{r}
k <- 20
vol_mat <- apply(Z_0, 2, function(x) zoo::rollapply(x, width = k, sd, align = "right", fill = NA))

vol_mean <- rowMeans(vol_mat, na.rm = TRUE)      # average vol across assets

plot(dates, vol_mean, type = "l", xlab = "time", ylab = "rolling sd",
     main = paste("Average rolling volatility (k=", k, ")", sep=""))

legend("topright", legend = "mean", lty = c(1,2), bty = "n")
```

## GIF of average volatility

```{r}
library(zoo)
library(gifski)

# 1) Rolling volatility
k <- 20
dates <- as.Date(df_clean$X)

vol_mat <- apply(Z_0, 2, function(x)
  rollapply(x, width = k, sd, align = "right", fill = NA)
)

vol_mean <- rowMeans(vol_mat, na.rm = TRUE)

# common y-limits so the plot doesn't jump
ylim_common <- range(vol_mean, na.rm = TRUE)

# 2) Build GIF: same number of frames as time points
Ts <- seq_along(vol_mean)   # one frame per time index

save_gif({
  par(mar = c(4, 4, 3, 1))

  for (t in Ts) {
    # base plot: full volatility line
    plot(dates, vol_mean,
         type = "l",
         xlab = "time",
         ylab = "rolling sd",
         main = paste("Average rolling volatility (k=", k, ")", sep = ""),
         ylim = ylim_common)

    axis.Date(1,
              at = seq(min(dates), max(dates), by = "year"),
              format = "%Y")

    legend("topright", legend = "mean", lty = 1, bty = "n")
    # ---- t + month/year label ----
    lab_date <- format(dates[t], "%b %Y")  # e.g. "Mar 2020"
    usr <- par("usr")
    x0  <- usr[1]
    y0  <- usr[4]

    # small offsets as % of width/height
    x_offset <- 0.04 * (usr[2] - usr[1])   # move right
    y_offset <- 0.04 * (usr[4] - usr[3])   # move down

    text(
      x0 + x_offset,
      y0 - y_offset,
      labels = paste0("t = ", t, "   ", lab_date),
      adj = c(0, 1),   # left, top
      xpd = NA,
      cex = 1.4
    )
    # moving red dot (skip if NA at start due to rolling window)
    if (!is.na(vol_mean[t])) {
      points(dates[t], vol_mean[t], col = "red", pch = 19, cex = 1.4)
    }
  }
}, gif_file = "rolling_vol_with_dot.gif",
   width = 900, height = 600, delay = 0.08)

```


## Unique number of edges over time

```{r}
edge_counts_all <- sapply(seq_along(res$icov), function(k) {
  M <- res$icov[[k]]
  sum(abs(M)[upper.tri(M)] > 1e-6)
})

plot(dates, edge_counts_all, type = "l", xlab = "t", ylab = "Number of unique edges", main = "Unique number of edges over time")

```